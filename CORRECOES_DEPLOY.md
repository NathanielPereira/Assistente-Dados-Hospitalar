# üîß Corre√ß√µes Aplicadas - Deploy para Produ√ß√£o

## üìã Resumo das Corre√ß√µes

Este documento descreve as corre√ß√µes aplicadas para resolver os problemas em produ√ß√£o.

### 1. ‚úÖ Modelo Google Gemini Atualizado

**Problema**: O modelo `gemini-pro` n√£o est√° mais dispon√≠vel na API v1beta do Google (erro 404).

**Solu√ß√£o**: Atualizado para `gemini-1.5-flash` (modelo gratuito e est√°vel).

**Arquivos modificados**:
- `apps/backend-fastapi/src/services/llm_service.py`

**Mudan√ßas**:
- Modelo padr√£o alterado de `gemini-pro` para `gemini-1.5-flash`
- Adicionado fallback para `gemini-1.5-pro` se flash falhar
- Adicionado fallback final sem especificar modelo (deixa biblioteca escolher)

### 2. ‚úÖ Reconex√£o Autom√°tica do Banco de Dados

**Problema**: Conex√µes perdidas causavam falhas ("the connection is lost").

**Solu√ß√£o**: Implementado sistema de reconex√£o autom√°tica com retry.

**Arquivos modificados**:
- `apps/backend-fastapi/src/database.py`

**Mudan√ßas**:
- Teste de conex√£o antes de usar
- Reconex√£o autom√°tica se conex√£o estiver perdida
- Retry autom√°tico (at√© 2 tentativas) em `execute_query` para erros de conex√£o
- Melhor tratamento de exce√ß√µes de conex√£o

### 3. ‚úÖ Mensagens de Erro Melhoradas

**Problema**: Erros de LLM ou banco n√£o retornavam informa√ß√µes claras ao frontend.

**Solu√ß√£o**: Mensagens de erro detalhadas e espec√≠ficas por tipo de problema.

**Arquivos modificados**:
- `apps/backend-fastapi/src/api/routes/chat.py`

**Mudan√ßas**:
- Detec√ß√£o de tipo de erro (LLM vs banco de dados)
- Mensagens espec√≠ficas quando nenhum LLM est√° dispon√≠vel
- Status de todos os provedores configurados
- Sugest√µes de a√ß√£o para cada tipo de erro

## üöÄ Instru√ß√µes para Deploy

### Op√ß√£o 1: Deploy Autom√°tico via Git (Recomendado)

Se o Render j√° est√° conectado ao seu reposit√≥rio GitHub, basta fazer push:

```bash
# Verificar status
git status

# Adicionar arquivos modificados
git add apps/backend-fastapi/src/services/llm_service.py
git add apps/backend-fastapi/src/database.py
git add apps/backend-fastapi/src/api/routes/chat.py

# Commit das corre√ß√µes
git commit -m "fix: Corrige modelo Google Gemini e reconex√£o de banco de dados

- Atualiza modelo de gemini-pro para gemini-1.5-flash (modelo v√°lido)
- Implementa reconex√£o autom√°tica do banco de dados
- Melhora mensagens de erro para usu√°rios

Resolve erros:
- 404 models/gemini-pro is not found
- Connection lost errors
- Mensagens de erro pouco informativas"

# Push para o reposit√≥rio (Render far√° deploy autom√°tico)
git push origin main
```

### Op√ß√£o 2: Deploy Manual via Render Dashboard

1. Acesse [Render Dashboard](https://dashboard.render.com)
2. Selecione o servi√ßo `hospital-assistant-backend`
3. V√° em "Manual Deploy" ‚Üí "Deploy latest commit"
4. Ou fa√ßa upload dos arquivos modificados

### Op√ß√£o 3: Usando Render CLI (se configurado)

```bash
# Instalar Render CLI (se ainda n√£o instalado)
npm install -g render-cli

# Fazer deploy
render deploy
```

## ‚úÖ Verifica√ß√£o P√≥s-Deploy

Ap√≥s o deploy, verifique os logs do Render:

1. **Acesse os logs do servi√ßo no Render Dashboard**
2. **Procure por estas mensagens**:
   - ‚úÖ `gemini-1.5-flash` (n√£o mais `gemini-pro`)
   - ‚úÖ `Inicializados X provedores de LLM`
   - ‚úÖ Sem erros de "404 models/gemini-pro"

3. **Teste o sistema**:
   ```bash
   # Health check
   curl https://assistente-dados-hospitalar.onrender.com/health
   
   # Teste de chat
   curl "https://assistente-dados-hospitalar.onrender.com/v1/chat/stream?session_id=test&prompt=Qual%20a%20taxa%20de%20ocupa%C3%A7%C3%A3o%20da%20UTI%20pedi%C3%A1trica%3F"
   ```

## üìù Notas Importantes

- **Vari√°veis de Ambiente**: Certifique-se de que `GOOGLE_API_KEY` est√° configurada no Render
- **Tempo de Deploy**: O deploy pode levar 5-10 minutos no Render
- **Rollback**: Se necess√°rio, voc√™ pode fazer rollback no dashboard do Render

## üîç Troubleshooting

Se ainda houver problemas ap√≥s o deploy:

1. **Verifique os logs do Render** para mensagens de erro espec√≠ficas
2. **Confirme as vari√°veis de ambiente** est√£o configuradas corretamente
3. **Teste a conex√£o do banco de dados** separadamente
4. **Verifique se o modelo est√° sendo usado corretamente** nos logs

---

**Data**: $(date)
**Vers√£o**: 1.0.0
