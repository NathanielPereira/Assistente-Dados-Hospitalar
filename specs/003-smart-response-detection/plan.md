# Implementation Plan: Smart Response Detection

**Branch**: `003-smart-response-detection` | **Date**: 2024-11-26 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/003-smart-response-detection/spec.md`

**Note**: This plan is generated by the `/speckit.plan` command. Execution workflow defined in `.specify/templates/commands/plan.md`.

## Summary

This feature enables the hospital data assistant to intelligently detect when user questions cannot be answered with available database data (e.g., asking about clinical protocols when only bed/appointment data exists). Instead of returning irrelevant SQL or generic errors, the system will:

1. Automatically detect PostgreSQL schema via `information_schema`
2. Extract entities from user questions and map them to schema
3. Calculate confidence score to determine if question is answerable
4. Provide clear explanations when data doesn't exist
5. Suggest 3 alternative questions based on actual schema
6. Adapt automatically as database schema evolves (within 1 hour)

**Technical Approach**: Cache-first architecture with in-memory schema cache (1-hour TTL), simple string-based entity extraction and matching (no ML), template-based suggestion generation, and integration into existing SQL agent pipeline as a pre-generation analysis step.

## Technical Context

**Language/Version**: Python 3.11  
**Primary Dependencies**: FastAPI, asyncpg (via existing database.py), Pydantic  
**Storage**: PostgreSQL (existing) + in-memory cache for schema  
**Testing**: pytest (existing test infrastructure)  
**Target Platform**: Linux server (Docker container)  
**Project Type**: Web application (backend API)  
**Performance Goals**: 
- Schema detection: < 100ms (cached), < 500ms (fresh)
- Question analysis: < 500ms total
- Complete smart response generation: < 1 second
- API endpoint impact: < 100ms added latency

**Constraints**: 
- No breaking changes to existing API contracts
- Must work with existing streaming SSE format
- Schema cache must be thread-safe for concurrent requests
- Fail-open: when in doubt, attempt to answer rather than reject

**Scale/Scope**: 
- Support schemas with up to 100 tables
- Cache footprint: < 10MB for schema metadata
- Expected load: same as existing chat endpoint (concurrent requests)
- ~500 lines of new service code + integration modifications

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

- ✅ **Proteção Integral de Dados Clínicos**: 
  - **Base legal**: Feature does NOT process patient data directly, only database metadata (table/column names)
  - **Minimização**: Only stores schema structure (no actual data values)
  - **Criptografia**: Operates on metadata; user questions logged via existing audit logger (already compliant)
  - **Controles**: Inherits from existing API authentication/authorization

- ✅ **Auditoria Automatizada e Rastreamento**: 
  - **Eventos rastreáveis**: Each question analysis logged with: question_id, entities_found, entities_missing, confidence_score, decision (answer/reject)
  - **Hash/ID**: Reuses existing session_id from chat API
  - **Storage imutável**: Uses existing audit_logger.py (append-only)
  - **Exportação**: Analysis decisions included in existing chat audit exports

- ✅ **Evidências e Testes Dirigindo Entregas**: 
  - **Datasets sintéticos**: Will create test fixtures with known schema + questions (answerable/unanswerable)
  - **Métricas-alvo**: 90% detection accuracy, 70% suggestion relevance, < 5% false positives
  - **Testes antes de código**: Quickstart will define test cases first (TDD approach)
  - **Regressão estatística**: Track confidence score distribution in tests

- ⚠️ **Interoperabilidade Modular Hospitalar**: 
  - **Contratos versionados**: Adds new internal service interfaces (SchemaDetector, QuestionAnalyzer) + optional response fields to chat API
  - **Breaking changes**: None - smart responses use same SSE format as current responses
  - **Adaptadores**: N/A - no external integrations
  - **Justificativa**: Internal services only, no breaking changes to public API

- ✅ **Observabilidade e Resiliência Operacional**: 
  - **SLOs**: p95 < 1s for analysis, 99.5% availability (inherits from chat API)
  - **Métricas**: `smart_response_analysis_duration_ms`, `schema_cache_hits`, `unanswerable_questions_count`
  - **Alertas**: Alert if schema detection fails > 3 consecutive times OR confidence calculation errors > 5% of requests
  - **Feature flags**: `ENABLE_SMART_DETECTION` env var (default: true)
  - **Circuit breaker**: If schema detection fails, use last valid cached schema (degraded mode)
  - **Playbook**: See research.md for recovery procedures

## Project Structure

### Documentation (this feature)

```text
specs/003-smart-response-detection/
├── plan.md              # This file (/speckit.plan output)
├── research.md          # Phase 0 output (technology decisions & best practices)
├── data-model.md        # Phase 1 output (entity definitions)
├── quickstart.md        # Phase 1 output (TDD test scenarios)
├── contracts/           # Phase 1 output (API schemas)
│   └── api.yaml         # OpenAPI additions for /v1/schema/info endpoint
└── tasks.md             # Phase 2 output (/speckit.tasks - NOT created yet)
```

### Source Code (repository root)

```text
apps/backend-fastapi/
├── src/
│   ├── services/
│   │   ├── schema_detector_service.py      # NEW: FR1 - Schema detection & caching
│   │   ├── question_analyzer_service.py    # NEW: FR2, FR3, FR4 - Entity extraction & mapping
│   │   ├── suggestion_generator_service.py # NEW: FR6 - Generate alternative questions
│   │   └── (existing services)
│   │
│   ├── domain/
│   │   ├── schema_info.py                  # NEW: SchemaInfo, TableInfo, ColumnInfo models
│   │   ├── question_analysis.py            # NEW: QuestionAnalysis, SmartResponse models
│   │   └── (existing domain models)
│   │
│   ├── agents/
│   │   └── sql_agent.py                    # MODIFIED: FR7 - Add pre-generation analysis
│   │
│   ├── api/
│   │   └── routes/
│   │       ├── chat.py                     # MODIFIED: FR8 - Stream smart responses
│   │       ├── schema.py                   # NEW: GET /v1/schema/info endpoint
│   │       └── (existing routes)
│   │
│   └── config.py                           # MODIFIED: Add CONFIDENCE_THRESHOLD, SCHEMA_CACHE_TTL
│
└── tests/
    ├── unit/
    │   ├── test_schema_detector_service.py
    │   ├── test_question_analyzer_service.py
    │   └── test_suggestion_generator_service.py
    │
    ├── integration/
    │   ├── test_smart_detection_flow.py    # End-to-end: question → analysis → response
    │   └── test_schema_refresh.py          # Schema cache TTL & refresh
    │
    └── contract/
        └── test_chat_api_backward_compat.py # Ensure no breaking changes
```

**Structure Decision**: Using existing web application structure (backend-fastapi). New services follow established pattern in `src/services/`. Domain models in `src/domain/`. Integration point is `src/agents/sql_agent.py` (pre-SQL generation) and `src/api/routes/chat.py` (response streaming). New `/v1/schema/info` endpoint added to `src/api/routes/schema.py` for schema inspection.

## Complexity Tracking

> **No violations requiring justification.** All constitution principles are satisfied without exceptions.

---

## Implementation Phases

### Phase 0: Research & Technology Decisions

**Objective**: Resolve all technical unknowns and document best practices for implementation.

**Research Tasks**:

1. **String Similarity Algorithms**:
   - Question: Which string matching algorithm provides best balance of accuracy/performance for Portuguese entity matching?
   - Evaluate: Levenshtein distance, Jaro-Winkler, SequenceMatcher (difflib)
   - Criteria: Performance (< 10ms per comparison), accuracy with Portuguese terms, no external dependencies

2. **Portuguese Stop Words**:
   - Question: Which stop words should be filtered for entity extraction in healthcare context?
   - Research: Common Portuguese stop words + domain-specific terms (qual, quantos, como, etc.)
   - Output: Definitive list for `question_analyzer_service.py`

3. **Synonym Mapping Strategy**:
   - Question: How to manage synonym mappings (hardcoded vs. configurable)?
   - Options: Dict in code, JSON config file, database table
   - Criteria: Maintainability, performance, ease of updates

4. **Thread-Safe Caching**:
   - Question: Best pattern for thread-safe in-memory cache in FastAPI/asyncio context?
   - Evaluate: asyncio.Lock, threading.RLock, simple dict (if immutable)
   - Criteria: Thread safety, performance, simplicity

5. **Schema Detection Optimization**:
   - Question: Single query vs. multiple queries for `information_schema`?
   - Research: PostgreSQL `information_schema` query performance patterns
   - Criteria: Minimize round trips, < 500ms total time

**Deliverable**: `research.md` with decisions and rationale for each research task.

---

### Phase 1: Design & Contracts

**Prerequisites**: `research.md` complete

#### 1.1 Data Model Design

**Objective**: Define all Pydantic models for schema representation and question analysis.

**Models to Create** (see spec Key Entities section):
- `SchemaInfo`: Complete database schema metadata
- `TableInfo`: Single table metadata
- `ColumnInfo`: Single column metadata
- `QuestionAnalysis`: Result of analyzing a user question
- `SmartResponse`: Response structure for unanswerable questions

**Output**: `data-model.md` with:
- Full model definitions with field types and validation rules
- Relationships between models
- Examples of serialized JSON for each model
- State transitions (if applicable, e.g., schema cache lifecycle)

#### 1.2 API Contract Design

**Objective**: Define OpenAPI spec for new endpoint and document modifications to existing endpoints.

**New Endpoints**:
- `GET /v1/schema/info` - Returns current cached schema
  - Response: `SchemaInfo` JSON
  - Headers: `X-Cache-Age` (seconds since last refresh)
  - Status codes: 200 (success), 503 (schema detection failed, using stale cache)

**Modified Endpoints** (no breaking changes):
- `GET /v1/chat/stream` - Can now return smart responses
  - New SSE event types: `schema_mismatch`, `suggestion`
  - Backward compatible: existing clients ignore unknown event types

**Output**: `contracts/api.yaml` - OpenAPI 3.0 spec fragment

#### 1.3 Quickstart / Test Scenarios

**Objective**: Define TDD test cases BEFORE implementation.

**Test Scenarios** (from spec User Scenarios & Testing):
1. Question about non-existent data → smart response
2. Question using synonyms → clarification + answer
3. Schema changes → automatic detection within TTL
4. Ambiguous question → guidance + examples
5. Partial match (some entities found) → partial answer + note

**Output**: `quickstart.md` with:
- Setup instructions (test fixtures, database schema)
- Test case definitions (given/when/then format)
- Expected outcomes with specific assertions
- Performance benchmarks

#### 1.4 Agent Context Update

**Objective**: Update Cursor agent memory with new technologies from this feature.

**Action**: Run `.specify/scripts/bash/update-agent-context.sh cursor-agent`

**Expected Additions**:
- Schema detection patterns
- Entity extraction approach
- Confidence scoring algorithm
- Integration points in sql_agent.py and chat.py

**Output**: Updated `.specify/memory/agent-context-cursor.md` (or similar)

---

### Phase 2: Task Breakdown

**Status**: ⏸️ **NOT EXECUTED IN THIS COMMAND**  
**Next Command**: `/speckit.tasks specs/003-smart-response-detection/plan.md`

This phase will break down the implementation into atomic tasks with dependencies and time estimates.

**Expected Output** (from `/speckit.tasks`):
- `tasks.md` with:
  - Task ID, description, dependencies, estimated effort
  - Implementation order respecting dependencies
  - Test tasks for each component

---

## Success Validation

**How to verify this plan is complete before implementation**:

1. ✅ All research questions have concrete answers in `research.md`
2. ✅ All models have complete Pydantic definitions in `data-model.md`
3. ✅ API contracts are documented in `contracts/api.yaml`
4. ✅ Test scenarios are defined in `quickstart.md` with pass/fail criteria
5. ✅ Constitution check passes (no violations OR justified exceptions)
6. ✅ Agent context updated with new technologies

**Gate for Phase 2 (Tasks)**: All Phase 1 deliverables must be complete and reviewed.

---

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| Schema detection too slow (> 500ms) | Medium | High | Use single optimized query + cache; add index hints if needed |
| False positives (rejecting answerable questions) | Medium | Medium | Tune confidence threshold (default 70%); log all decisions for analysis |
| Cache memory footprint exceeds 10MB | Low | Low | Implement LRU eviction if schema > 100 tables; monitor in production |
| Synonym mapping incomplete | High | Low | Start with minimal set (5-10 common terms); extend based on user feedback |
| Breaking changes to chat API | Low | High | Use same SSE format; add integration tests to verify backward compatibility |
| Schema changes not detected within 1 hour | Low | Medium | Validate TTL mechanism in integration tests; add manual refresh endpoint for emergencies |

**Critical Path**: Schema detection performance → Entity extraction accuracy → Suggestion relevance

**Blocker Dependencies**: None - feature is self-contained addition to existing system.

---

## Notes

### Design Principles Applied

1. **Fail-Open**: When confidence is borderline (60-70%), system attempts to answer rather than reject
2. **Cache-First**: Schema cached in memory to minimize database load
3. **Simple > Complex**: String matching instead of ML embeddings for maintainability
4. **Template-Based**: Suggestions use predefined templates to ensure they're always valid
5. **Non-Breaking**: All changes are additive; existing API behavior unchanged

### Integration Points

- **sql_agent.py**: Add `analyze_question()` call before `generate_sql()`
- **chat.py**: Add `stream_smart_response()` path when `can_answer == False`
- **config.py**: Add `CONFIDENCE_THRESHOLD`, `SCHEMA_CACHE_TTL_SECONDS`
- **audit_logger.py**: Log analysis decisions with `event_type="question_analysis"`

### Performance Considerations

- Schema cache refresh is async and non-blocking
- Entity extraction uses simple string operations (no regex)
- Confidence calculation is O(n) where n = number of entities
- Suggestion generation uses pre-compiled templates

### Future Extensibility

- Synonym mappings can be moved to database table later
- Confidence algorithm can be swapped without API changes
- Template system can be enhanced with dynamic generation
- Schema detection can add support for multiple databases

---

**Status**: ✅ Plan complete, ready for Phase 0 (Research)  
**Next Step**: Execute research tasks to resolve all NEEDS CLARIFICATION items  
**Command to Continue**: (Research will be executed automatically as part of this planning phase)

